---
title: "Bootstrap"
output: 
  html_document: 
    toc: yes
---

```{r}
library(tidyverse)
```

# The Bootstrap

- The bootstrap is a flexible and powerful statistical tool that can be used to quantify the uncertainty associated with a given estimator or statistical learning method.
- It can provide an estimate of the standard error of a coefficient, or a confidence interval for that coefficient.

## In the ideal world
 
- For example, we have an estimator $\hat \alpha$ of $\alpha$ and we are interested in its s.d. (to construct confidence interval)
  - $\hat \alpha$ is a function of the observations $(x_i,y_i)$, $i=1,\ldots,n$
  - To estimate the standard deviation of $\hat \alpha$, we could simulate
      observations $(\tilde x_i, \tilde y_i)$, $i=1,\ldots,n$ which have the same distribution as $(x_i,y_i)$.
  - A new estimate of $\alpha$ is obtained, called it $\tilde \alpha$
  - repeat the process 1000 times, we have 1000 $\tilde \alpha$'s and the sample deviations of
    those 1000 $\tilde \alpha$'s can be used to estimate the s.d. of $\hat \alpha$.
    
-  The procedure outlined above cannot be applied, because for real data we cannot generate new samples from the original population.
    
## Now back to the real world

- However, the bootstrap approach allows us to use a computer to mimic the process of obtaining new data sets, so that we can estimate the variability of our estimate without generating additional samples.
- Rather than repeatedly obtaining independent data sets from the population, we instead
        obtain distinct data sets by repeatedly sampling observations from the original data set *with replacement*.
- Each of these 'bootstrap data sets' is created by sampling with replacement, and is the same size as our original dataset. As a result some observations may appear more than once in a given bootstrap data set and some not at all.

## Example with just 3 observations

```{r echo=FALSE, out.width='80%'}
knitr::include_graphics("boot3.png")
```

## Notations

- Denoting the first bootstrap data set by $Z^{*1}$, we use $Z^{*1}$ to
produce a new bootstrap estimate for $\alpha$, which we call $\hat \alpha^{*1}$
- this procedure is repeated $B$ times for some large value of $B$ (say 5000 or 10000)
- we have $B$ different bootstrap data sets, $Z^{*1},\ldots,Z^{*B}$, and $B$
       corresponding $\alpha$ estimates, $\hat \alpha^{*1},\ldots,\hat \alpha^{*B}$
- We estimate the standard error of these bootstrap estimates using the formula
$$
 SE_{B}(\hat \alpha) = \sqrt{\frac{1}{B-1}\sum_{r=1}^{B} (\hat \alpha^{*r} - \bar{\hat
 \alpha}^*)^2}
$$
where $\bar{\hat \alpha}^*$ is the average of $\hat \alpha^{*r}$'s.

- This serves as an estimate of the standard error of $\hat \alpha$ estimated from the original data set.

       
## A general picture for the bootstrap
```{r echo=FALSE, out.width='100%'}
knitr::include_graphics("bootstrap_world.png")
```


## A example

```{r}
mtcars %>%
  summarize(r = cor(mpg, hp)) %>%
  pull(r)
```

To get the "classical" confidence interval (by Fisher's transformation)

```{r}
with(mtcars, cor.test(mpg, hp))
```

Use bootstrap to obtain a confidence interval

# Classical boostrap confidence interval

Bootstrap is used to obtain standard errors of an estimate.


```{r}
library(rsample)
boots <- bootstraps(mtcars, times = 10000)
```

```{r}
se <- boots %>%
  pull(splits) %>%
  map_dbl(
    ~ {
      train_data <- analysis(.)
      with(train_data, cor(mpg, hp))
    }
  ) %>%
  sd()

with(mtcars, cor(mpg, hp)) + 1.96 * c(-1, 1) * se
```

where `qnorm(0.975)` is roughly 1.96.


If you want to do it manually

```{r}
se <- map_dbl(seq_len(10000), ~{
    n <- nrow(mtcars)
    index <- sample.int(n, n, replace = TRUE)
    x <- mtcars$mpg[index]
    y <- mtcars$hp[index]
    cor(x, y)
}) %>% sd()

with(mtcars, cor(mpg, hp)) + 1.96 * c(-1, 1) * se
```


### Bootstrap Percentile confidence interval

- Consider the 2.5th and 97.5th percentile of $\hat \alpha^{*1},\ldots,\hat \alpha^{*B}$
- The above interval is called a 95% Bootstrap Percentile confidence interval.
- It usually gives better results for heavily skewed distributions of statistics.

```{r}
boots %>%
  pull(splits) %>%
  map_dbl(
    ~ {
      train_data <- analysis(.)
      with(train_data, cor(mpg, hp))
    }
  ) %>%
  quantile(p = c(0.025, 0.975))
```


## Using `parallel` to do bootstrap (the conventional approach)

First thing first, we don't want to use `bootstraps()` function for parallel processing because it will make deep copy of the bootstrap datasets. We will do a more primitive resampling using `sample.int`.

```{r}
library(parallel)
cl <- makeCluster(4)
```

```{r}
B <- 10000

rs <- parSapply(cl, seq_len(B), function(i) {
  n <- nrow(mtcars)
  index <- sample.int(n, n, replace = TRUE)
  x <- mtcars$mpg[index]
  y <- mtcars$hp[index]
  cor(x, y)
})

rs %>% quantile(c(0.025, 0.975))
```

```{r}
stopCluster(cl)  # stop the cluster finally
```


## Using `furrr` to do bootstrap (my recommendation over parSapply/parLapply)

```{r}
library(furrr)
suppressWarnings(plan(multiprocess, workers = 4))
```

```{r}
B <- 10000
seq_len(B) %>% future_map_dbl(function(i) {
    n <- nrow(mtcars)
    index <- sample.int(n, n, replace = TRUE)
    x <- mtcars$mpg[index]
    y <- mtcars$hp[index]
    cor(x, y)
}) %>%
  quantile(c(0.025, 0.975))
```


# Reference

- rsample: https://tidymodels.github.io/rsample/
- Chapter 5 of An Introduction to Statistical Learning http://faculty.marshall.usc.edu/gareth-james/ISL/
