---
title: "Parallel"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache = TRUE)
```

```{r, message = TRUE}
library(tidyverse)
```

# Parallel Computation


## Implict Parallelization via linear algebra library

- BLAS (Basic Linear Algebra Subroutines)
  - CRAN R ships with a [version](https://github.com/wch/r-source/tree/trunk/src/extra/blas) 
    of single threaded BLAS library.
  - [Microsoft R Open](https://mran.microsoft.com/open) ships with 
    Intel MKL (Win/Linux) / Accelerate ML (macOS) BLAS libraries.
  - on macOS, R could be configured to use the optimized BLAS from Apple's Accelerate framework
  - We could also install R with different BLAS libraries such as 
    [openblas](https://github.com/xianyi/OpenBLAS) or [ATLAS](http://math-atlas.sourceforge.net/)


## Embarrassingly Parallel

Also called perfectly parallel, delightfully parallel or pleasingly parallel. 

> An embarrassingly parallel task can be considered a trivial case - little or no manipulation is needed to separate the problem into a number of parallel tasks.

A bit deroute first - revisit some of our old friends `map` and `map_*` in `purrr`.

```{r}
1:4 %>% map(function(x) x^2)
1:4 %>% map_dbl(function(x) x^2)
1:4 %>% map_dbl(~ .^2)
```

These are the base R equivalence.
```{r}
1:4 %>% lapply(function(x) x^2)
1:4 %>% sapply(function(x) x^2)
```


Suppose we have a list of vectors and we want to operation some operation on each vector.

```{r}
# it is a slow operation, imagine that in real applications, it could take a few minutes
slow_task <- function(x) {
  sum(x %o% x)
}

list_of_vectors <- replicate(10, list(rnorm(5000)))
list_of_vectors %>% glimpse()
```


```{r, eval = FALSE}
list_of_vectors %>% map_dbl(slow_task)
```

However, these commands only run in a single process, it means, if the list is doubled, the time is also at least doubled.

```{r}
system.time({
  list_of_vectors %>% map_dbl(slow_task)
})

# double the list
longer_list_of_vectors <- c(list_of_vectors, list_of_vectors)
system.time({
  longer_list_of_vectors %>% map_dbl(slow_task)
})
```

We are hoping to use multiple processes to speed up the job. The **conventional** way is to use the `parallel` package.

## The package `parallel`

```{r}
library(parallel)
```

Consider again the above list_vector example,
```{r}
# the number of cores we have
detectCores()
# it will create a socket cluster on my own computer
cl <- makeCluster(4)
parLapply(cl, list_of_vectors, slow_task)
# or if you want simplified result
parSapply(cl, list_of_vectors, slow_task)
# stop the cluster after use
stopCluster(cl)
```

Remark: you don't have to make and stop clusters for every operation, you could make a cluster in the very beginning of your script and close it at the very end.


Let's test the speed improvement

```{r, paged.print = FALSE}
run_each <- function(x, fun, n_cores) {
  cl <- makeCluster(n_cores)
  result <- parLapply(cl, x, fun)
  stopCluster(cl)
  result
}

bench::mark(
  longer_list_of_vectors %>% map(slow_task),
  run_each(longer_list_of_vectors, slow_task, 2),
  run_each(longer_list_of_vectors, slow_task, 4),
  run_each(longer_list_of_vectors, slow_task, 8)
)
```
PS: it is not always true that the more cpus, the faster the result.


### Processing Chunk

The tasks are divided into chunks before sending the chunks to the workers. `Sys.getpid()` tells us the process id of a worker.

```{r}
cl <- makeCluster(4)
```

```{r}
parSapply(cl, 1:10, function(x) {
  Sys.getpid()
})
parSapply(cl, 1:10, function(x) {
    Sys.getpid()
  },
  chunk.size = 2
)
parSapply(cl, 1:10, function(x) {
    Sys.getpid()
  },
  chunk.size = 1
)
```

```{r}
stopCluster(cl)
```


### Load balancing


`parLapply` pre-schedules the tasks to each work. It could be suboptimal when different tasks require different amount of time to complete.

```{r}
cl <- makeCluster(4)
```

```{r}
x <- c(3, 3, 1, 1, 1, 1, 1, 1, 1, 1) # length 10
pause <- function(x) {
  Sys.sleep(x)
}

system.time({
  map(x, pause)  # sequentially, 14 seconds
})

system.time({
  parLapply(cl, x, pause)  # process 1 runs task 1, 2, 3
})
system.time({
  parLapply(cl, x, pause, chunk.size = 2)  # process 1 runs task 1, 2, 9, 10
})
system.time({
  parLapply(cl, x, pause, chunk.size = 1)  # process 1 runs task 1, 5, 9
})
```

Instead of preshceduling the tasks, a task could only be assigned to a free worker dynamically using `parLapplyLB`.

```{r}
system.time({
  parLapplyLB(cl, x, pause, chunk.size = 1)
})
```
Note that it only takes 4 seconds now.


```{r}
stopCluster(cl)
```


### Caution

We need to make sure that objects are available in the cluster

```{r}
cl <- makeCluster(4)
```

```{r}
y <- 10
add <- function(x) {
  x + y
}
```

```{r}
sapply(1:10, add)
```

```{r, error = TRUE}
parSapply(cl, 1:10, add)
```

```{r}
clusterExport(cl, "y")
parSapply(cl, 1:10, add)
```

```{r}
stopCluster(cl)
```


### Interact directly with the workers

We just saw an quick example on using `parLapply/parSapply`. Let's try a few more things.

```{r}
cl <- makeCluster(4)
```


We could run some arbitrary commands on each of the workers
```{r}
clusterEvalQ(cl, {
  x <- rnorm(100)
  mean(x)
})
```

```{r}
clusterEvalQ(cl, {
  Sys.getpid()
})
```

If you want to set a random seed, the following doesn't work because each work returns the same result.


```{r}
# wrong
set.seed(123)
clusterEvalQ(cl, {
  rnorm(5)
})
# wrong again
clusterEvalQ(cl, {
  set.seed(123)
  rnorm(5)
})
```

```{r}
clusterSetRNGStream(cl, 1234)
clusterEvalQ(cl, {
  rnorm(5)
})
```

```{r}
# do not forget to close the cluster
stopCluster(cl)
```

## Fork cluster vs socket cluster

In the R `parallel` package, there are two common implementations of paralllization via `makeCluster`, e.g. fork and socket (default in RStudio).


For the fork, each parallel thread is a "complete" duplication of the master process with the shared environment, including objects or variables defined prior to the kickoff of parallel processes. Therefore, it runs fast. However, the major limitation is that the fork doesnâ€™t work on the Windows system.
(Also, it is not very stable in RStudio.)

```{r, eval = FALSE}
y <- 2
cl <- makeForkCluster(4)
clusterEvalQ(cl, {
  y
})
stopCluster(cl)
```

On the other hand, the socket works on all operating systems. Each process runs separately without sharing objects or variables, which can only be passed from the master process explicitly. As a result, it runs slower due to the communication overhead.

```{r, eval = FALSE}
y <- 2
cl <- makePSOCKcluster(4)
clusterEvalQ(cl, {
  y
})
stopCluster(cl)
```

- thread: need RcppParallel
  thread vs fork vs process
  In python, `threading` in python uses threads to do parallels tasks.

- coroutine (asynchronous programming):
  Different to parallelization.
  In R: library `coro`
  In python: `asyncio`


Ref: https://www.r-bloggers.com/parallel-r-socket-or-fork/


## `mclapply` from `parallel` (unix / macOS only)

`mclapply` relies on forking, it means that it doesn't work on Windows. As it uses forking,
we don't have to export global variables.

```{r}
m <- matrix(rnorm(16), 4, 4)
mclapply(
  1:4,
  function(i) sum(m[i, ]),
  mc.cores = 4
)
```
is more or less equivalent to
```{r}
cl <- makeForkCluster(4)
parLapply(cl, 1:4, function(i) sum(m[i, ]))
stopCluster(cl)
```



```{r}
# in default, `mclapply` uses 2 cores
system.time({
  mclapply(
    c(3, 3, 1, 1, 1, 1, 1, 1),
    function(x) Sys.sleep(x),
    mc.cores = 4
  )
})

system.time({
  mclapply(
    c(3, 3, 1, 1, 1, 1, 1, 1),
    function(x) Sys.sleep(x),
    mc.preschedule = FALSE, #  set FALSE to enable load balancing
    mc.cores = 4
  )
})
```


## Package: `foreach`

As we have seen a bit earlier, we might need to use `clusterExport` to export certain global variables in a socket cluster. It would be a bit cumbersome. To reduce the extra steps, we could consider `foreach` and `doParallel`. They will send all the globals to the workers before running the tasks. (However, I don't personally recommend `foreach` though it is (was!?) popular, I prefer `furrr` in the below)

```{r}
library(foreach)
library(doParallel)
```

```{r}
cl <- makeCluster(4)
registerDoParallel(cl)

m <- matrix(rnorm(16), 4, 4)
# matrix m is sent to the workers implicitly
# in fact, all variables in the current (global) environment are sent to the workers in default
foreach(i = seq_len(nrow(m)), .combine = c) %dopar% {
  sum(m[i, ])
}
stopCluster(cl)
```
is almost equivalent to

```{r}
cl <- makeCluster(4)
clusterExport(cl, ls(envir = environment()))
parSapply(cl, seq_len(nrow(m)), function(i) {
  sum(m[i, ])
})
invisible(clusterEvalQ(cl, {
  rm(m)
}))
stopCluster(cl)
```


However, it is not quite "functional" as `mclapply`. `foreach` sends all the global variabels to the workers (which may be not optimal)

## Package `furrr`

`furrr` provides functions which are very similar to those in `purrr`.
One nice thing about `furrr` is that it doesn't send absolutely all global variables to the workers as `foreach` and `mclapply`. It does lexical analysis to deduce what objects are needed and only transfer them to the workers. It also loads libraries automatically in the workers.


```{r}
m <- matrix(rnorm(16), 4, 4)

# purrr
seq_len(nrow(m)) %>% 
  map(~ sum(m[., ]))
```


```{r}
library(furrr)
```

```{r, message = FALSE, warning = FALSE}
# to use 4 workers, `plan(multiprocess)` will use all the available workers
plan(multiprocess, workers = 4)
```

```{r}
# furrr
seq_len(nrow(m)) %>% 
  future_map(~ sum(m[., ]))
```

`future_map` has a family of type specific functions. For example,
```{r}
seq_len(nrow(m)) %>% 
  future_map_dbl(~ sum(m[., ]))
```


load balancing in `future_map`

```{r}
# without load balanacing
system.time({
  future_map(
    c(3, 3, 1, 1, 1, 1, 1, 1),
    ~ Sys.sleep(.)
  )
})

# with load balancing
system.time({
  future_map(
    c(3, 3, 1, 1, 1, 1, 1, 1),
    ~ Sys.sleep(.),
    .options = future_options(scheduling = FALSE)
  )
})
```



## Divide and conquer a.k.a. mapreduce

Divide and conquer allows a single task operation to be executed parallelly.

```{r, echo = FALSE}
DiagrammeR::grViz("mapreduce.gv", height = 200)
```

In assignment 2 how we could use map and reduce to compute the mean. However, we didn't
really do the calculations parallelly. We are going to use the `furrr` library.


There are two ways to get data to the workers in cluster:

- Partition a data set that already loaded in the main process.
  - It may not be possible to load the whole data set into a main process.
- Load a different subset of the data in each worker.
  - It is the most realistic situation and it is more memory efficient


In order to mimic the second situation, we need some preparation.
```{r}
# we first random split `flights` into 10 files
library(nycflights13)
set.seed(141)
m <- 10
groups <- sample(seq_len(m), nrow(flights), replace = TRUE)
dir.create("flights/", showWarnings = FALSE)
for (i in seq_len(m)) {
  write_csv(filter(flights, groups == i), str_c("flights/", i, ".csv"))
}
```

We are going to perform the calculations via two approaches

- The conventional approach by using `parLapply`
- A newer approach by using `furrr`

### The conventional approach

```{r}
file_names <- file.path("flights", list.files("flights"))
m <- length(file_names)
```

```{r}
library(parallel)
cl <- makeCluster(4)
# we will to manually load tidyverse in the workers
invisible(clusterEvalQ(cl, {
  library(tidyverse)
  NULL
}))
```

```{r}
mean_list <- parLapply(cl, file_names, function(fname) {
    df <- read_csv(fname, col_types = cols())
    mean(df$dep_delay, na.rm = TRUE)
})

(mean_dep_delay <- mean_list %>% reduce(`+`) / m)
```


```{r}
stopCluster(cl)
```


### By using `furrr`

```{r}
library(furrr)
suppressWarnings(plan(multiprocess, workers = 4))
options(future.rng.onMisuse = "ignore")
```


```{r}
file_names <- file.path("flights", list.files("flights"))
m <- length(file_names)

mean_list <- file_names %>% future_map(~{
  df <- read_csv(., col_types = cols())
  mean(df$dep_delay, na.rm = TRUE)
})

(mean_dep_delay <- mean_list %>% reduce(`+`) / m)
```

### More efficient file reading by using `vroom`.

See: https://vroom.r-lib.org/

```{r}
library(vroom)
```

```{r, paged.print = FALSE, message = FALSE}
bench::mark(
  read.csv("flights/1.csv"),
  read_csv("flights/1.csv"),
  vroom("flights/1.csv"),
  read_csv("flights/1.csv", col_types = cols()),
  vroom("flights/1.csv", col_types = cols()),
  read_csv("flights/1.csv", col_types = cols_only(dep_delay = col_double())),
  vroom("flights/1.csv", col_types = cols(), col_select = c(dep_delay)),
  check = FALSE
)
```


```{r}
mean_list <- file_names %>% future_map(~{
  df <- vroom(., col_types = cols())
  mean(df$dep_delay, na.rm = TRUE)
})

(mean_dep_delay <- mean_list %>% reduce(`+`) / m)
```

```{r, paged.print = FALSE}
bench::mark(
  read_csv = {
    mean_list <- file_names %>% future_map(~{
      df <- read_csv(., col_types = cols())
      mean(df$dep_delay, na.rm = TRUE)
    })
  },
  vroom = {
    mean_list <- file_names %>% future_map(~{
      df <- vroom(., col_types = cols())
      mean(df$dep_delay, na.rm = TRUE)
    })
  }
)
```



Reference:

- R Programming for Data Science https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html
